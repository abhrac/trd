<!DOCTYPE html>
<html>
   <head>
      <style>
         td, th {
         border: 0px solid black;
         }
         img{
         padding: 5px;
         }
      </style>
      <title>TRD</title>
      <!-- Global site tag (gtag.js) - Google Analytics -->
      <!--  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
         <script>
           window.dataLayer = window.dataLayer || [];
         
           function gtag() {
             dataLayer.push(arguments);
           }
         
           gtag('js', new Date());
         
           gtag('config', 'G-PYVRSFMDRL');
         
         
         
         </script> -->
      <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
         rel="stylesheet">
      <link rel="stylesheet" href="./static/css/bulma.min.css">
      <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
      <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
      <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
      <link rel="stylesheet"
         href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
      <link rel="stylesheet" href="./static/css/index.css">
      <link rel="icon" href="./static/images/favicon.svg">
      <link rel="stylesheet" href="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.css">
      <link rel="stylesheet" href="css/app.css">
      <link rel="stylesheet" href="css/bootstrap.min.css">
      <script src="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.js"></script>
      <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
      <script defer src="./static/js/fontawesome.all.min.js"></script>
      <script src="./static/js/bulma-carousel.min.js"></script>
      <script src="./static/js/bulma-slider.min.js"></script>
      <script src="./static/js/index.js"></script>
   </head>
   <!-- <body>
      <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
          <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>
        </div>
        <div class="navbar-menu">
          <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
            <a class="navbar-item" href="https://keunhong.com">
            <span class="icon">
                <i class="fas fa-home"></i>
            </span>
            </a>
      
            <div class="navbar-item has-dropdown is-hoverable">
              <a class="navbar-link">
                More Research
              </a>
              <div class="navbar-dropdown">
                <a class="navbar-item" href="https://hypernerf.github.io">
                  HyperNeRF
                </a>
                <a class="navbar-item" href="https://nerfies.github.io">
                  Nerfies
                </a>
                <a class="navbar-item" href="https://latentfusion.github.io">
                  LatentFusion
                </a>
                <a class="navbar-item" href="https://photoshape.github.io">
                  PhotoShape
                </a>
              </div>
            </div>
          </div>

        </div>
      </nav> -->
   <section class="hero">
      <div class="hero-body">
         <div class="container is-max-desktop">
            <div class="columns is-centered">
               <div class="column has-text-centered">
                  <!-- <h1 class="title is-1 publication-title", style="color:purple;">Picture that Sketch:</h1> -->
                  <h1 class="title is-1 publication-title">Transitivity Recovering Decompositions: <nobr>Interpretable and Robust Fine-Grained Relationships </nobr>
                  </h1>
                  <div class="is-size-5 publication-authors">
                     <span class="author-block">
                     <a href="https://sites.google.com/view/abhrachaudhuri/">Abhra Chaudhuri</a><sup>1,5,6</sup>, &nbsp;</span>
                     <span class="author-block">
                     <a href="https://mancinimassimiliano.github.io/">Massimiliano Mancini</a><sup>2</sup>, &nbsp;</span>
                     <span class="author-block">
                     <a href="https://www.eml-unitue.de/people/zeynep-akata">Zeynep Akata</a><sup>3,4</sup>, &nbsp;</span>	  
                     <span class="author-block">
                        <a href="https://www.surrey.ac.uk/people/anjan-dutta">Anjan Dutta</a><sup>5,6</sup></span>	     
                  </span>
                  </div>
                  <div class="is-size-5 publication-authors">
                     <span class="author-block"><sup>1</sup>University of Exeter &nbsp;</span>
                     <!-- <span class="author-block">&nbsp;&nbsp;&nbsp;&nbsp;</span> -->
                     <span class="author-block"><sup>2</sup>University of Trento &nbsp;</span>
                     <span class="author-block"><sup>3</sup>University of TÃ¼bingen &nbsp;</span>
                     <br>
                     <span class="author-block"><sup>4</sup>MPI for Informatics &nbsp;</span>
                     <span class="author-block"><sup>5</sup>The Alan Turing Institute &nbsp;</span>
                     <span class="author-block"><sup>6</sup>University of Surrey &nbsp;</span>
                  </div>
                  <!--     <div class="column has-text-centered">
                     <a href="as">ICLR 2023</a>
                     </span>
                     </div> -->
                  <div class="column has-text-centered">
                     <div class="publication-links">
                        <!-- PDF Link. -->
                        <span class="link-block">
                        <a href="https://openreview.net/forum?id=wUNPmdE273"
                           class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                        </a>
                        </span>
                        <!-- <span class="link-block">
                        <a href="https://arxiv.org/abs/2303.11162"
                           class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                        <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                        </a>
                        </span> -->
                        <!-- Video Link. -->
                        <!-- <span class="link-block">
                        <a href=""
                           class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                        <i class="fab fa-youtube"></i>
                        </span>
                        <span>Video</span>
                        </a>
                        </span> -->
                        <!-- Code Link. -->
                        <span class="link-block">
                        <a href="https://github.com/abhrac/trd"
                           class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                        <i class="fab fa-github"></i>
                        </span>
                        <span>Code</span>
                        </a>
                        </span>
                        <!-- Dataset Link. -->
                        <!-- <span class="link-block">
                           <a href=""
                              class="external-link button is-normal is-rounded is-dark">
                             <span class="icon">
                                 <i class="far fa-images"></i>
                             </span>
                             <span>Data</span>
                           </a> -->
                     </div>
                  </div>
               </div>
            </div>
         </div>
      </div>
   </section>
   <section class="hero teaser">
      <div class="container is-max-desktop">
         <div class="hero-body">
            <center>
               <img class="round" style="width:900px" src="./static/images/trd/model_diagram.png"/>
            </center>
            <h2 class="subtitle has-text-centered">
               <span class="dnerf"></span>  Instead of learning representations of emergent relationships that are abstract aggregations
               of views, our method deconstructs the input, latent, and the class representation (proxy) spaces into
               graphs, thereby ensuring that all stages along the inference path are interpretable.
            </h2>
         </div>
      </div>
   </section>

   <!-- Paper video. -->
   <!-- <section class="section">
      <div class="container is-max-desktop">
         <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">      
            <h2 class="title is-3">Video</h2>
            <iframe width="560" height="315" src="https://www.youtube.com/embed/LhWn7Ga8Y_c" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
         </div>
      </div>
   </div>
</section> -->

   <!-- Poster -->
   <!-- <section class="section">
      <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
         <div class="column is-four-fifths">
            <h2 class="title is-3">Poster</h2>
            <div class="content has-text-justified">
               </h2>
               <center>
                  <a href="https://cvpr2023.thecvf.com/media/PosterPDFs/CVPR%202023/22658.png?t=1685109677.757326"><img src="./static/images/dfsbir/poster.png" alt="" border=0 height=300 width=650></img></a></
               </center>
               &nbsp; 
            </div>
         </div>
      </div>
   </section>
   <section class="section">
   <div class="container is-max-desktop"> -->

   <!-- Abstract. -->
   <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
         <h2 class="title is-3">Abstract</h2>
         <div class="content has-text-justified">
            Recent advances in fine-grained representation learning leverage local-to-global
            (emergent) relationships for achieving state-of-the-art results. The relational representations relied upon by such methods, however, are abstract. We aim to
            deconstruct this abstraction by expressing them as interpretable graphs over image
            views. We begin by theoretically showing that abstract relational representations
            are nothing but a way of recovering transitive relationships among local views.
            Based on this, we design Transitivity Recovering Decompositions (TRD), a graphspace search algorithm that identifies interpretable equivalents of abstract emergent
            relationships at both instance and class levels, and with no post-hoc computations.
            We additionally show that TRD is provably robust to noisy views, with empirical
            evidence also supporting this finding. The latter allows TRD to perform at par or
            even better than the state-of-the-art, while being fully interpretable. Implementation
            is available at <a href="https://github.com/abhrac/trd">https://github.com/abhrac/trd</a>.
            </p>
         </div>
      </div>
   </div>

   <!-- Model -->
   <!-- <section class="section">
      <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
         <div class="column is-four-fifths">
            <h2 class="title is-3">Method</h2>
            <div class="content has-text-justified">
               </h2>
               <center>
                  <img src="./static/images/dfsbir/df_sbir_model-1.png" alt="" border=0 height=300 width=650></img></
               </center>
               <div class="subtitle has-text-centered">
                  The photo and sketch estimators reconstruct the train set distributions
                  of their corresponding classifiers, which could then be used to train the downstream encoders.
                  The estimation process is ensured to have semantic consistency and completeness (through adversarial estimation) and class-level, instance-wise correspondence
                  while maintaining modality boundaries.
               </div>
               &nbsp; 
            </div>
         </div>
      </div>
   </section> -->
   

   <!-- <section class="hero">
   <div class="hero-body">
   <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
         <div class="column is-four-fifths">
            <h2 class="title is-3">Results</h2>
            <div class="content has-text-justified">
               <center>
                  <img src="static/images/dfsbir/qualitative_results-1.png" alt="this slowpoke moves" border=0 height=1000 width=2000/>
               </center>
               <div class="subtitle has-text-centered">
                  Data-free photo and sketch reconstructions of the Sketchy and TU-Berlin datasets produced by our estimator networks.
               </div>
			   <br>
			   <br>			
               <center>
                  <img src="static/images/dfsbir/qualitative_ablation_class_alignment-1.png" alt="this slowpoke moves" border=0 height=200 width=600/>
               </center>
               <div class="subtitle has-text-centered">
                  Photo and sketch reconstructions without (left) and with (right) the Class-Alignment loss. Each column corresponds to a
                  single reconstruction step using a common input noise vector fed in to the photo and sketch estimators respectively.
               </div>
			   <br>
			   <br>
               <center>
                  <img src="static/images/dfsbir/qualitative_ablation_modality_guidance-1.png" alt="this slowpoke moves" border=0 height=200 width=400/>
               </center>
               <div class="subtitle has-text-centered">
                  Reconstructed photos and sketches of an Apple in the presence and absence of the Modality Guidance loss.
               </div>
			   <br>
			   <br>
			   <center>
                  <img src="static/images/dfsbir/qualitative_ablation_adversarial_estimation-1.png" alt="this slowpoke moves" border=0 height=200 width=500/>
               </center>
               <div class="subtitle has-text-centered">
                  Reconstructions obtained by using Metric-Agnostic Adversarial Estimation, with respective
                  class-scores assigned by the teacher and the student.
               </div>
			   <br>
			   <br>
			   <center>
                  <img src="static/images/dfsbir/partial_overlap_web.png" alt="this slowpoke moves" border=0 height=400 width=800/>
               </center>
               <div class="subtitle has-text-centered">
                  DF-SBIR performance of our model when the classifiers (teachers) are trained on only partially overlapping sets of classes.
               </div>
			   <br>
			   <br>
            <center>
               <img src="static/images/dfsbir/reconstruction_quality-1.png" alt="this slowpoke moves" border=0 height=400 width=800/>
            </center>
            <div class="subtitle has-text-centered">
               Variation in mAP@all, as well as reconstruction quality across epochs.
            </div>
         <br>
         <br>
         </div>
      </div>
   </div> -->

   <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
         <h2 class="title">BibTeX</h2>
         <pre><code>
            @inproceedings{
               chaudhuri2023TRD,
               title={Transitivity Recovering Decompositions: Interpretable and Robust Fine-Grained Relationships},
               author={Abhra Chaudhuri and Massimiliano Mancini and Zeynep Akata and Anjan Dutta},
               booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
               year={2023},
               url={https://openreview.net/forum?id=wUNPmdE273}
          }
         </code></pre>
      </div>
   </section>
   <script>
      const viewers = document.querySelectorAll(".image-compare");
      viewers.forEach((element) => {
          let view = new ImageCompare(element, {
              hoverStart: true,
              addCircle: true
          }).mount();
      });
      
      $(document).ready(function () {
          var editor = CodeMirror.fromTextArea(document.getElementById("bibtex"), {
              lineNumbers: false,
              lineWrapping: true,
              readOnly: true
          });
          $(function () {
              $('[data-toggle="tooltip"]').tooltip()
          })
      });
   </script>
   <br>
   <p style="text-align:center"> Last updated: 30 November 2023 | Template Credit: <a href="https://nerfies.github.io/"> Nerfies</a></p>
   </body>
</html>
